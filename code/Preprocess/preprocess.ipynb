{"cells":[{"cell_type":"markdown","metadata":{},"source":"# Demo for the SMILES processing"},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":"########################################################\n# All rights reserved. \n# Author: XIE Zhengwei @ Beijing Gigaceuticals Tech Co., Ltd \n#                      @ Peking University International Cancer Institute\n# Contact: xiezhengwei@gmail.com\n#\n#\n########################################################\n\nimport sys\nsys.path.append('../DLEPS')\nimport molecule_vae\nfrom rdkit.Chem import MolFromSmiles, MolToSmiles\nfrom rdkit.Chem import Draw\n\nimport numpy as np  \nimport pandas as pd\n"},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":"dt1 = pd.read_csv('../../data/train_SMILES_demo.csv')\ndt2 = pd.read_csv('../../data/test_SMILES_demo.csv')\n\nsmiles = np.concatenate([dt1['SMILES'].values, dt2['1'].values],axis=0) \n    "},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["array(['NC(=O)NCC#Cc1ccc2NC(=O)[C@@]3([C@H]([C@H]4N([C@H]3c5ccc(OCCO)cc5)[C@@H]([C@@H](OC4=O)c6ccccc6)c7ccccc7)C(=O)NCC=C)c2c1',\n","       'COc1cccc(NC(=O)N2[C@H]3CNC[C@@H]2[C@@H]3c2ccc(cc2)-c2ccncc2)c1',\n","       'COc1ccc2c3c([C@H](CO)N(C[C@]33CCN(Cc4nccs4)CC3)C(=O)NC(C)C)n(C)c2c1',\n","       ...,\n","       'OC[C@@H]1O[C@@H](CC(=O)NCCN2CCCCC2)C[C@H]2[C@@H]1Oc1ccc(NC(=O)c3ccc4OCOc4c3)cc21',\n","       'CN(C)CCCNc1c2ccccc2n(C)c2nc(=O)n(C)c(=O)c12',\n","       'COc1cccc(c1)C(=O)N1C[C@@H]2[C@@H]([C@H](CO)N2C(=O)c2ccc(F)cc2)c2ccccc12'],\n","      dtype=object)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":"smiles"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":42,"metadata":{"scrolled":true},"outputs":[],"source":"#list(smiles)"},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["COc1ccc2c3c([C@H](CO)N(C[C@]33CCN(Cc4nccs4)CC3)C(=O)NC(C)C)n(C)c2c1\n"]},{"data":{"text/plain":["'COc1ccc2c3c(n(C)c2c1)[C@H](CO)N(C(=O)NC(C)C)CC31CCN(Cc2nccs2)CC1'"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":"print(smiles[2])\nMolToSmiles(MolFromSmiles(smiles[2]))"},{"cell_type":"code","execution_count":25,"metadata":{"scrolled":true},"outputs":[],"source":"#smiles = smiles[:100]\nsmiles_rdkit = []\niid = []\nfor i in range(len(smiles)):\n    try:\n        smiles_rdkit.append(MolToSmiles(MolFromSmiles(smiles[ i ])))\n        iid.append(i)\n        #print(i)\n    except:\n        print(\"Error at %d\" % (i))\n        "},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1400\n","1400\n"]}],"source":"print(len(smiles))\nprint(len(iid))"},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":"#smiles_rdkit"},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":"def get_zinc_tokenizer(cfg):\n    long_tokens = [a for a in list(cfg._lexical_index.keys()) if xlength(a) > 1] ####\n    replacements = ['$','%','^'] # ,'&']\n    assert xlength(long_tokens) == len(replacements) ####xzw\n    for token in replacements: \n        assert token not in cfg._lexical_index ####\n    \n    def tokenize(smiles):\n        for i, token in enumerate(long_tokens):\n            smiles = smiles.replace(token, replacements[i])\n        tokens = []\n        for token in smiles:\n            try:\n                ix = replacements.index(token)\n                tokens.append(long_tokens[ix])\n            except:\n                tokens.append(token)\n        return tokens\n    \n    return tokenize\n"},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":"from functools import reduce\n\ndef xlength(y):\n    return reduce(lambda sum, element: sum + 1, y, 0)\n"},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":"import zinc_grammar\nimport nltk\n\n_tokenize = get_zinc_tokenizer(zinc_grammar.GCFG)\n_parser = nltk.ChartParser(zinc_grammar.GCFG)\n_productions = zinc_grammar.GCFG.productions()\n_prod_map = {}\nfor ix, prod in enumerate(_productions):\n    _prod_map[prod] = ix\nMAX_LEN = 277\n_n_chars = len(_productions)\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":"smiles_rd = smiles_rdkit[:100]"},{"cell_type":"code","execution_count":40,"metadata":{"scrolled":false},"outputs":[{"name":"stdout","output_type":"stream","text":["Too large molecules, out of range\n","Too large molecules, out of range\n","Too large molecules, out of range\n","Too large molecules, out of range\n","Too large molecules, out of range\n","Too large molecules, out of range\n","Too large molecules, out of range\n","Too large molecules, out of range\n","Too large molecules, out of range\n","Too large molecules, out of range\n","Too large molecules, out of range\n","Too large molecules, out of range\n","Too large molecules, out of range\n","Too large molecules, out of range\n","Too large molecules, out of range\n","Too large molecules, out of range\n","Too large molecules, out of range\n","Too large molecules, out of range\n","Too large molecules, out of range\n","Too large molecules, out of range\n","Too large molecules, out of range\n","Too large molecules, out of range\n","Too large molecules, out of range\n","Too large molecules, out of range\n","Too large molecules, out of range\n","Too large molecules, out of range\n"]}],"source":"        \"\"\" Encode a list of smiles strings into the latent space \"\"\"\n        assert type(smiles_rdkit) == list\n        tokens = map(_tokenize, smiles_rdkit)\n        parse_trees = []\n        i = 0\n        badi = []\n        for t in tokens:\n            #while True:\n            try:\n                tp = next(_parser.parse(t))\n                parse_trees.append(tp)\n            except:\n                print(\"Parse tree error at %d\" % i)\n                badi.append(i)\n            i += 1\n            #print(i)\n        productions_seq = [tree.productions() for tree in parse_trees]\n        indices = [np.array([_prod_map[prod] for prod in entry], dtype=int) for entry in productions_seq]\n        one_hot = np.zeros((len(indices), MAX_LEN, _n_chars), dtype=np.float32)\n        for i in range(len(indices)):\n            num_productions = len(indices[i])\n            if num_productions > MAX_LEN:\n                print(\"Too large molecules, out of range\")\n            #print(\"i=  {%d} len(indices)=  {%d} num_productions = %d \" % (i,len(indices),num_productions))\n                one_hot[i][np.arange(MAX_LEN),indices[i][:MAX_LEN]] = 1.\n            else:    \n                one_hot[i][np.arange(num_productions),indices[i]] = 1.\n                one_hot[i][np.arange(num_productions, MAX_LEN),-1] = 1."},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"data":{"text/plain":["1400"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":"iix = np.arange(len(smiles_rdkit))\niidx = [i for i in iix if i not in badi]\nlen(iidx)\niid2 = np.array(iid)[iidx]\nlen(iid2)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(17051, 978)\n"]}],"source":"#L962 = np.genfromtxt('L1000.csv', delimiter=',')\n#L962 = L962[iid2]\n#print(L962.shape)\n#num_examples = L962.shape[0]"},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":"perm = np.arange(num_examples)\nnp.random.shuffle(perm)\n#L962 = L962[perm]\nsmile_rd = one_hot[perm]\nTEST_SIZE = 3000\n#L962_train = L962[TEST_SIZE:]\nsmile_train = smile_rd[TEST_SIZE:]\n#L962_test = L962[:TEST_SIZE]\nsmile_test = smile_rd[:TEST_SIZE]"},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":"#savetxt(fname, X, fmt='%.18e', delimiter=' ', newline='\\n', header='', footer='', comments='# ', encoding=None)[source]\n#np.savetxt(\"L1000_train.csv\",L962_train, delimiter = ',')\n#np.savetxt(\"L1000_test.csv\",L962_test, delimiter = ',')"},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":"#import h5py\n\n#h5f = h5py.File('SMILE_train_demo.h5', 'w')\n#h5f.create_dataset('data', data=smile_train)\n#h5f.close()\n\n#h5f = h5py.File('SMILE_test_demo.h5', 'w')\n#h5f.create_dataset('data', data=smile_test)\n#h5f.close()\n\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":2}